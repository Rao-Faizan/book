"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[3009],{482:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>t,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"module2/chapter10","title":"Chapter 10: Sim-to-Real Transfer","description":"Bridge the reality gap with domain randomization, system identification, and progressive transfer techniques for deploying simulated policies on real robots","source":"@site/docs/module2/chapter10.mdx","sourceDirName":"module2","slug":"/module2/chapter10","permalink":"/book/docs/module2/chapter10","draft":false,"unlisted":false,"editUrl":"https://github.com/Rao-Faizan/book/tree/master/docs/module2/chapter10.mdx","tags":[],"version":"current","sidebarPosition":10,"frontMatter":{"title":"Chapter 10: Sim-to-Real Transfer","description":"Bridge the reality gap with domain randomization, system identification, and progressive transfer techniques for deploying simulated policies on real robots","sidebar_position":10},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 9: Sensor Simulation","permalink":"/book/docs/module2/chapter9"},"next":{"title":"Module 3: The AI-Robot Brain","permalink":"/book/docs/category/module-3-the-ai-robot-brain"}}');var s=r(4848),l=r(8453);const a={title:"Chapter 10: Sim-to-Real Transfer",description:"Bridge the reality gap with domain randomization, system identification, and progressive transfer techniques for deploying simulated policies on real robots",sidebar_position:10},t="Chapter 10: Sim-to-Real Transfer",o={},d=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"The Reality Gap Problem",id:"the-reality-gap-problem",level:2},{value:"Why the Gap Exists",id:"why-the-gap-exists",level:3},{value:"Domain Randomization: The Solution",id:"domain-randomization-the-solution",level:2},{value:"Core Idea",id:"core-idea",level:3},{value:"Types of Domain Randomization",id:"types-of-domain-randomization",level:2},{value:"1. Visual Randomization",id:"1-visual-randomization",level:3},{value:"2. Physics Randomization",id:"2-physics-randomization",level:3},{value:"3. Sensor Randomization",id:"3-sensor-randomization",level:3},{value:"4. Object Randomization",id:"4-object-randomization",level:3},{value:"Complete Domain Randomization Pipeline",id:"complete-domain-randomization-pipeline",level:2},{value:"Reinforcement Learning Training Loop",id:"reinforcement-learning-training-loop",level:3},{value:"System Identification",id:"system-identification",level:2},{value:"What to Identify",id:"what-to-identify",level:3},{value:"Example: Friction Identification",id:"example-friction-identification",level:3},{value:"Progressive Transfer Learning",id:"progressive-transfer-learning",level:2},{value:"Three-Stage Approach",id:"three-stage-approach",level:3},{value:"Stage 1: Pure Simulation",id:"stage-1-pure-simulation",level:3},{value:"Stage 2: Simulation + Real Data",id:"stage-2-simulation--real-data",level:3},{value:"Stage 3: Fine-Tuning on Real Robot",id:"stage-3-fine-tuning-on-real-robot",level:3},{value:"Validation Metrics",id:"validation-metrics",level:2},{value:"Quantitative Metrics",id:"quantitative-metrics",level:3},{value:"Comparison Table",id:"comparison-table",level:3},{value:"Case Studies",id:"case-studies",level:2},{value:"Case Study 1: OpenAI Dactyl (Rubik&#39;s Cube)",id:"case-study-1-openai-dactyl-rubiks-cube",level:3},{value:"Case Study 2: ANYmal Quadruped Locomotion",id:"case-study-2-anymal-quadruped-locomotion",level:3},{value:"Practical Tips for Reducing Reality Gap",id:"practical-tips-for-reducing-reality-gap",level:2},{value:"Design Principles",id:"design-principles",level:3},{value:"Debugging Sim-to-Real Failures",id:"debugging-sim-to-real-failures",level:3},{value:"Complete Example: Sim-to-Real Bipedal Walking",id:"complete-example-sim-to-real-bipedal-walking",level:2},{value:"Training Script with Full DR",id:"training-script-with-full-dr",level:3},{value:"Summary",id:"summary",level:2},{value:"\ud83c\udfaf Key Takeaways",id:"-key-takeaways",level:3},{value:"\ud83d\udd04 Sim-to-Real Workflow",id:"-sim-to-real-workflow",level:3},{value:"Hands-On Exercise",id:"hands-on-exercise",level:2},{value:"Task: Train and Deploy Robust Controller",id:"task-train-and-deploy-robust-controller",level:3},{value:"Further Resources",id:"further-resources",level:2},{value:"Research Papers",id:"research-papers",level:3},{value:"Tools",id:"tools",level:3},{value:"Community",id:"community",level:3},{value:"Congratulations! \ud83c\udf89",id:"congratulations-",level:2},{value:"What You&#39;ve Learned:",id:"what-youve-learned",level:3},{value:"Module 2 Summary:",id:"module-2-summary",level:3},{value:"What&#39;s Next?",id:"whats-next",level:2}];function c(e){const n={a:"a",admonition:"admonition",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"chapter-10-sim-to-real-transfer",children:"Chapter 10: Sim-to-Real Transfer"})}),"\n",(0,s.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsx)(n.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Analyze"})," sources of the reality gap between simulation and real robots"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Implement"})," domain randomization to create robust policies"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Perform"})," system identification to calibrate simulation parameters"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Apply"})," progressive transfer learning from simulation to reality"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Validate"})," sim-to-real transfer with quantitative metrics"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Design"})," experiments to minimize the reality gap"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Deploy"})," simulation-trained AI to real humanoid robots"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Prerequisites"}),": Chapters 6-9 (Complete Module 2)",(0,s.jsx)(n.br,{}),"\n",(0,s.jsx)(n.strong,{children:"Estimated Time"}),": 60 minutes"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"the-reality-gap-problem",children:"The Reality Gap Problem"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Reality Gap"}),": The difference between simulated and real-world robot behavior."]}),"\n",(0,s.jsx)(n.h3,{id:"why-the-gap-exists",children:"Why the Gap Exists"}),"\n",(0,s.jsx)(n.p,{children:"No simulator perfectly models reality due to:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Physics Approximations"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Contact dynamics (friction, bouncing)"}),"\n",(0,s.jsx)(n.li,{children:"Deformable objects (cloth, soft materials)"}),"\n",(0,s.jsx)(n.li,{children:"Fluid dynamics (air resistance, water)"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Sensor Discrepancies"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Noise patterns don't match exactly"}),"\n",(0,s.jsx)(n.li,{children:"Lighting conditions impossible to replicate"}),"\n",(0,s.jsx)(n.li,{children:"Calibration errors"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Actuator Differences"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Motor backlash and dead zones"}),"\n",(0,s.jsx)(n.li,{children:"Temperature-dependent performance"}),"\n",(0,s.jsx)(n.li,{children:"Battery voltage variations"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Environmental Factors"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Surface irregularities (no floor is perfectly flat)"}),"\n",(0,s.jsx)(n.li,{children:"Unexpected obstacles"}),"\n",(0,s.jsx)(n.li,{children:"Human behavior"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-mermaid",children:"graph TD\r\n    A[Sim-to-Real Gap] --\x3e B[Physics Gap]\r\n    A --\x3e C[Perception Gap]\r\n    A --\x3e D[Actuation Gap]\r\n    A --\x3e E[Environment Gap]\r\n    \r\n    B --\x3e F[Contact, Friction,<br/>Deformation]\r\n    C --\x3e G[Sensor Noise,<br/>Lighting]\r\n    D --\x3e H[Motor Delays,<br/>Backlash]\r\n    E --\x3e I[Surface Variation,<br/>Obstacles]\n"})}),"\n",(0,s.jsx)(n.admonition,{title:"The Challenge",type:"warning",children:(0,s.jsxs)(n.p,{children:["A policy that works perfectly in simulation might ",(0,s.jsx)(n.strong,{children:"completely fail"})," on a real robot if the reality gap isn't addressed."]})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"domain-randomization-the-solution",children:"Domain Randomization: The Solution"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Domain Randomization"}),": Vary simulation parameters during training so the learned policy becomes robust to real-world variations."]}),"\n",(0,s.jsx)(n.h3,{id:"core-idea",children:"Core Idea"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-mermaid",children:"graph LR\r\n    A[Training Episode 1:<br/>Friction=0.5] --\x3e D[Robust Policy]\r\n    B[Training Episode 2:<br/>Friction=0.8] --\x3e D\r\n    C[Training Episode 3:<br/>Friction=1.2] --\x3e D\r\n    D --\x3e E[Real World:<br/>Friction=0.7]\r\n    E --\x3e F[Success! \u2705]\r\n    \r\n    style D fill:#90EE90\r\n    style F fill:#FFD700\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"If trained policy works across randomized simulations, it will likely work in reality."})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"types-of-domain-randomization",children:"Types of Domain Randomization"}),"\n",(0,s.jsx)(n.h3,{id:"1-visual-randomization",children:"1. Visual Randomization"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"What to Randomize:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Textures (floor, walls, objects)"}),"\n",(0,s.jsx)(n.li,{children:"Lighting (intensity, color, position)"}),"\n",(0,s.jsx)(n.li,{children:"Camera parameters (exposure, distortion)"}),"\n",(0,s.jsx)(n.li,{children:"Background clutter"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Gazebo Example: Random Lighting"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import random\r\nfrom gazebo_msgs.srv import SetLightProperties\r\nfrom std_msgs.msg import ColorRGBA\r\n\r\nclass LightingRandomizer(Node):\r\n    def __init__(self):\r\n        super().__init__('lighting_randomizer')\r\n        self.client = self.create_client(SetLightProperties, '/world/default/set_light')\r\n        \r\n    def randomize_light(self):\r\n        # Random intensity (500-50000 Lux)\r\n        intensity = random.uniform(500, 50000)\r\n        \r\n        # Random color temperature\r\n        temp = random.uniform(2700, 6500)  # Warm to cool\r\n        color = self.temperature_to_rgb(temp)\r\n        \r\n        # Call Gazebo service\r\n        req = SetLightProperties.Request()\r\n        req.light_name = 'sun'\r\n        req.diffuse = ColorRGBA(r=color[0], g=color[1], b=color[2], a=1.0)\r\n        req.attenuation_constant = intensity\r\n        \r\n        self.client.call_async(req)\r\n        \r\n    def temperature_to_rgb(self, kelvin):\r\n        # Simplified color temperature conversion\r\n        if kelvin < 3000:\r\n            return [1.0, 0.8, 0.6]  # Warm\r\n        elif kelvin < 5000:\r\n            return [1.0, 1.0, 0.9]  # Neutral\r\n        else:\r\n            return [0.8, 0.9, 1.0]  # Cool\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Unity Example: Texture Randomization"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csharp",children:'using UnityEngine;\r\n\r\npublic class TextureRandomizer : MonoBehaviour\r\n{\r\n    public Material[] floorMaterials;  // Array of different floor textures\r\n    public Renderer floorRenderer;\r\n    \r\n    void OnEpisodeBegin()\r\n    {\r\n        // Randomly select floor texture\r\n        int randomIndex = Random.Range(0, floorMaterials.Length);\r\n        floorRenderer.material = floorMaterials[randomIndex];\r\n        \r\n        Debug.Log($"Randomized floor texture: {floorMaterials[randomIndex].name}");\r\n    }\r\n}\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"2-physics-randomization",children:"2. Physics Randomization"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"What to Randomize:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Friction coefficients"}),"\n",(0,s.jsx)(n.li,{children:"Mass and inertia"}),"\n",(0,s.jsx)(n.li,{children:"Joint damping and limits"}),"\n",(0,s.jsx)(n.li,{children:"Gravity (if testing on moon, Mars, etc.)"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Gazebo Physics Randomization:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import random\r\nfrom gazebo_msgs.srv import SetPhysicsProperties\r\n\r\nclass PhysicsRandomizer(Node):\r\n    def __init__(self):\r\n        super().__init__('physics_randomizer')\r\n        self.client = self.create_client(SetPhysicsProperties, '/set_physics_properties')\r\n    \r\n    def randomize_physics(self):\r\n        req = SetPhysicsProperties.Request()\r\n        \r\n        # Randomize gravity (Earth \xb110%)\r\n        gravity_multiplier = random.uniform(0.9, 1.1)\r\n        req.gravity.z = -9.81 * gravity_multiplier\r\n        \r\n        # Randomize physics timestep\r\n        req.time_step = random.uniform(0.0005, 0.002)\r\n        \r\n        # Randomize solver iterations\r\n        req.ode_config.sor_pgs_iters = random.randint(30, 100)\r\n        \r\n        self.client.call_async(req)\r\n        self.get_logger().info(f'Randomized gravity: {req.gravity.z:.2f} m/s\xb2')\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Friction Randomization in URDF:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'\x3c!-- Gazebo material properties with randomization --\x3e\r\n<gazebo reference="foot_link">\r\n  <mu1>0.8</mu1>  \x3c!-- Baseline friction --\x3e\r\n  <mu2>0.8</mu2>\r\n  <kp>1000000.0</kp>\r\n  <kd>100.0</kd>\r\n</gazebo>\n'})}),"\n",(0,s.jsx)(n.p,{children:"Then randomize at runtime:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"from gazebo_msgs.srv import SetLinkProperties\r\n\r\ndef randomize_friction(self, link_name):\r\n    req = SetLinkProperties.Request()\r\n    req.link_name = link_name\r\n    \r\n    # Randomize friction \xb130%\r\n    req.surface.friction.mu = random.uniform(0.56, 1.04)  # 0.8 \xb130%\r\n    req.surface.friction.mu2 = req.surface.friction.mu\r\n    \r\n    self.friction_client.call_async(req)\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"3-sensor-randomization",children:"3. Sensor Randomization"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"What to Randomize:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Camera noise, blur, exposure"}),"\n",(0,s.jsx)(n.li,{children:"LiDAR dropouts, noise"}),"\n",(0,s.jsx)(n.li,{children:"IMU bias and drift"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Camera Noise Randomization (Unity):"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csharp",children:'using UnityEngine.Rendering.PostProcessing;\r\n\r\npublic class CameraNoiseRandomizer : MonoBehaviour\r\n{\r\n    PostProcessVolume volume;\r\n    Grain grain;\r\n    \r\n    void Start()\r\n    {\r\n        volume = GetComponent<PostProcessVolume>();\r\n        volume.profile.TryGetSettings(out grain);\r\n    }\r\n    \r\n    void OnEpisodeBegin()\r\n    {\r\n        // Randomize grain intensity (sensor noise)\r\n        grain.intensity.value = Random.Range(0.1f, 0.5f);\r\n        \r\n        // Randomize grain size\r\n        grain.size.value = Random.Range(0.5f, 2.0f);\r\n        \r\n        Debug.Log($"Camera noise: {grain.intensity.value}");\r\n    }\r\n}\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"4-object-randomization",children:"4. Object Randomization"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"What to Randomize:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Object positions and orientations"}),"\n",(0,s.jsx)(n.li,{children:"Object sizes and shapes"}),"\n",(0,s.jsx)(n.li,{children:"Number of obstacles"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Gazebo Object Spawner:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"from gazebo_msgs.srv import SpawnEntity\r\nimport random\r\n\r\nclass ObjectRandomizer(Node):\r\n    def __init__(self):\r\n        super().__init__('object_randomizer')\r\n        self.spawn_client = self.create_client(SpawnEntity, '/spawn_entity')\r\n        \r\n    def spawn_random_obstacles(self, num_obstacles=5):\r\n        for i in range(num_obstacles):\r\n            # Random position within 5x5m area\r\n            x = random.uniform(-2.5, 2.5)\r\n            y = random.uniform(-2.5, 2.5)\r\n            z = 0.5  # Half-height above ground\r\n            \r\n            # Random size\r\n            size = random.uniform(0.3, 1.0)\r\n            \r\n            # Create box SDF\r\n            sdf = f\"\"\"\r\n            <sdf version='1.6'>\r\n              <model name='obstacle_{i}'>\r\n                <pose>{x} {y} {z} 0 0 0</pose>\r\n                <link name='link'>\r\n                  <collision name='collision'>\r\n                    <geometry>\r\n                      <box><size>{size} {size} {size}</size></box>\r\n                    </geometry>\r\n                  </collision>\r\n                  <visual name='visual'>\r\n                    <geometry>\r\n                      <box><size>{size} {size} {size}</size></box>\r\n                    </geometry>\r\n                  </visual>\r\n                </link>\r\n              </model>\r\n            </sdf>\r\n            \"\"\"\r\n            \r\n            req = SpawnEntity.Request()\r\n            req.name = f'obstacle_{i}'\r\n            req.xml = sdf\r\n            self.spawn_client.call_async(req)\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"complete-domain-randomization-pipeline",children:"Complete Domain Randomization Pipeline"}),"\n",(0,s.jsx)(n.h3,{id:"reinforcement-learning-training-loop",children:"Reinforcement Learning Training Loop"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'"""\r\nComplete DR training example for humanoid walking\r\n"""\r\nimport random\r\nimport gymnasium as gym\r\nfrom stable_baselines3 import PPO\r\n\r\nclass DomainRandomizedEnv(gym.Env):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.randomizers = [\r\n            self.randomize_physics,\r\n            self.randomize_textures,\r\n            self.randomize_lighting,\r\n            self.randomize_obstacles\r\n        ]\r\n    \r\n    def reset(self):\r\n        # Apply ALL randomizations every episode\r\n        for randomizer in self.randomizers:\r\n            randomizer()\r\n        \r\n        # Reset robot to initial state\r\n        self.robot.reset_position()\r\n        return self.get_observation()\r\n    \r\n    def step(self, action):\r\n        # Apply action to robot\r\n        self.robot.apply_action(action)\r\n        \r\n        # Get new observation\r\n        obs = self.get_observation()\r\n        reward = self.calculate_reward()\r\n        done = self.is_done()\r\n        \r\n        return obs, reward, done, {}\r\n    \r\n    def randomize_physics(self):\r\n        # Friction\r\n        self.set_friction(random.uniform(0.5, 1.2))\r\n        \r\n        # Joint damping\r\n        for joint in self.robot.joints:\r\n            joint.damping = random.uniform(0.1, 2.0)\r\n    \r\n    def randomize_textures(self):\r\n        textures = self.load_texture_library()\r\n        self.floor.texture = random.choice(textures)\r\n    \r\n    def randomize_lighting(self):\r\n        intensity = random.uniform(500, 50000)\r\n        self.set_light_intensity(intensity)\r\n    \r\n    def randomize_obstacles(self):\r\n        num_obstacles = random.randint(0, 10)\r\n        self.spawn_random_obstacles(num_obstacles)\r\n\r\n# Train with domain randomization\r\nenv = DomainRandomizedEnv()\r\nmodel = PPO("MlpPolicy", env, verbose=1)\r\nmodel.learn(total_timesteps=1000000)  # 1M steps with randomization\r\n\r\n# Save policy\r\nmodel.save("humanoid_walking_robust")\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"system-identification",children:"System Identification"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"System Identification"}),": Measure real robot parameters and update simulation to match."]}),"\n",(0,s.jsx)(n.h3,{id:"what-to-identify",children:"What to Identify"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Parameter"}),(0,s.jsx)(n.th,{children:"How to Measure"}),(0,s.jsx)(n.th,{children:"Sim Parameter"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Friction"})}),(0,s.jsx)(n.td,{children:"Slide object, measure deceleration"}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"<mu1>"}),", ",(0,s.jsx)(n.code,{children:"<mu2>"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Mass"})}),(0,s.jsx)(n.td,{children:"Weigh robot parts"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"<mass>"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Inertia"})}),(0,s.jsx)(n.td,{children:"Pendulum test"}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"<ixx>"}),", ",(0,s.jsx)(n.code,{children:"<iyy>"}),", ",(0,s.jsx)(n.code,{children:"<izz>"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Joint Damping"})}),(0,s.jsx)(n.td,{children:"Oscillation decay test"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"<damping>"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Motor Delays"})}),(0,s.jsx)(n.td,{children:"Command-to-motion timing"}),(0,s.jsx)(n.td,{children:"Actuator lag"})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"example-friction-identification",children:"Example: Friction Identification"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Experiment:"})}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Place robot on test surface"}),"\n",(0,s.jsx)(n.li,{children:"Apply known force"}),"\n",(0,s.jsx)(n.li,{children:"Measure resulting acceleration"}),"\n",(0,s.jsxs)(n.li,{children:["Calculate friction: ",(0,s.jsx)(n.code,{children:"F_friction = F_applied - m * a"})]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Implementation:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import numpy as np\r\n\r\nclass FrictionIdentifier:\r\n    def __init__(self, robot_mass=50.0):  # kg\r\n        self.mass = robot_mass\r\n        self.measurements = []\r\n    \r\n    def run_trial(self, applied_force, measured_acceleration):\r\n        """\r\n        applied_force: Force in Newtons\r\n        measured_acceleration: Measured acceleration in m/s\xb2\r\n        """\r\n        # F_friction = F_applied - ma\r\n        friction_force = applied_force - (self.mass * measured_acceleration)\r\n        \r\n        # Friction coefficient: \u03bc = F_friction / F_normal\r\n        # F_normal = mg (for flat surface)\r\n        normal_force = self.mass * 9.81\r\n        mu = friction_force / normal_force\r\n        \r\n        self.measurements.append(mu)\r\n    \r\n    def get_average_friction(self):\r\n        return np.mean(self.measurements), np.std(self.measurements)\r\n\r\n# Example usage\r\nidentifier = FrictionIdentifier(robot_mass=50.0)\r\n\r\n# Run 10 trials\r\nfor trial in range(10):\r\n    force = 100.0  # 100N push\r\n    accel = measure_robot_acceleration()  # From IMU\r\n    identifier.run_trial(force, accel)\r\n\r\nmu_avg, mu_std = identifier.get_average_friction()\r\nprint(f"Identified friction: \u03bc = {mu_avg:.3f} \xb1 {mu_std:.3f}")\r\n\r\n# Update Gazebo URDF\r\nupdate_urdf_friction(mu_avg)\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"progressive-transfer-learning",children:"Progressive Transfer Learning"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Strategy"}),": Gradually transition from simulation to reality."]}),"\n",(0,s.jsx)(n.h3,{id:"three-stage-approach",children:"Three-Stage Approach"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-mermaid",children:"graph LR\r\n    A[Stage 1:<br/>Pure Simulation<br/>1M episodes] --\x3e B[Stage 2:<br/>Partial Real Data<br/>100 episodes]\r\n    B --\x3e C[Stage 3:<br/>Fine-tune on Real<br/>50 episodes]\r\n    C --\x3e D[Deployed Policy \u2705]\r\n    \r\n    style A fill:#E8F4F8\r\n    style B fill:#FFF9C4\r\n    style C fill:#C8E6C9\r\n    style D fill:#FFD700\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"stage-1-pure-simulation",children:"Stage 1: Pure Simulation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Train entirely in sim with heavy DR\r\nenv_sim = DomainRandomizedEnv(randomization_strength=1.0)\r\nmodel = PPO("MlpPolicy", env_sim)\r\nmodel.learn(total_timesteps=1_000_000)\r\nmodel.save("stage1_sim_policy")\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"stage-2-simulation--real-data",children:"Stage 2: Simulation + Real Data"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Load sim policy\r\nmodel = PPO.load("stage1_sim_policy")\r\n\r\n# Create hybrid environment (80% sim, 20% real)\r\nenv_hybrid = HybridEnv(sim_ratio=0.8, real_ratio=0.2)\r\n\r\n# Continue training\r\nmodel.set_env(env_hybrid)\r\nmodel.learn(total_timesteps=100_000)  # Fewer steps needed\r\nmodel.save("stage2_hybrid_policy")\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"stage-3-fine-tuning-on-real-robot",children:"Stage 3: Fine-Tuning on Real Robot"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Load hybrid policy\r\nmodel = PPO.load("stage2_hybrid_policy")\r\n\r\n# Fine-tune on real robot only\r\nenv_real = RealRobotEnv()\r\nmodel.set_env(env_real)\r\nmodel.learn(total_timesteps=50_000)  # Careful - real robot wear!\r\nmodel.save("stage3_real_policy")\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"validation-metrics",children:"Validation Metrics"}),"\n",(0,s.jsx)(n.p,{children:"How do you know if sim-to-real transfer succeeded?"}),"\n",(0,s.jsx)(n.h3,{id:"quantitative-metrics",children:"Quantitative Metrics"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Success Rate"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Success Rate = (Successful Trials / Total Trials) \xd7 100%\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Trajectory Error"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def trajectory_error(sim_trajectory, real_trajectory):\r\n    """\r\n    Compare simulated vs. real robot paths\r\n    """\r\n    error = np.linalg.norm(sim_trajectory - real_trajectory, axis=1)\r\n    return np.mean(error)  # Average error in meters\n'})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Action Consistency"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def action_consistency(sim_actions, real_actions):\r\n    """\r\n    How similar are actions in sim vs. real?\r\n    """\r\n    correlation = np.corrcoef(sim_actions, real_actions)[0, 1]\r\n    return correlation  # 1.0 = perfect match\n'})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"comparison-table",children:"Comparison Table"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Metric"}),(0,s.jsx)(n.th,{children:"Simulation"}),(0,s.jsx)(n.th,{children:"Real Robot"}),(0,s.jsx)(n.th,{children:"Acceptable Gap"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Walk speed"}),(0,s.jsx)(n.td,{children:"0.8 m/s"}),(0,s.jsx)(n.td,{children:"0.7 m/s"}),(0,s.jsx)(n.td,{children:"\xb115%"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Energy efficiency"}),(0,s.jsx)(n.td,{children:"120 J/m"}),(0,s.jsx)(n.td,{children:"140 J/m"}),(0,s.jsx)(n.td,{children:"\xb120%"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Success rate (obstacle)"}),(0,s.jsx)(n.td,{children:"95%"}),(0,s.jsx)(n.td,{children:"80%"}),(0,s.jsx)(n.td,{children:"\xb115%"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Trajectory error"}),(0,s.jsx)(n.td,{children:"0 cm"}),(0,s.jsx)(n.td,{children:"5 cm"}),(0,s.jsx)(n.td,{children:"<10 cm"})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"case-studies",children:"Case Studies"}),"\n",(0,s.jsx)(n.h3,{id:"case-study-1-openai-dactyl-rubiks-cube",children:"Case Study 1: OpenAI Dactyl (Rubik's Cube)"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Challenge"}),": Train robotic hand to solve Rubik's Cube",(0,s.jsx)(n.br,{}),"\n",(0,s.jsx)(n.strong,{children:"Approach"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Massive domain randomization (size, friction, mass, colors)"}),"\n",(0,s.jsx)(n.li,{children:"100 years of simulated experience"}),"\n",(0,s.jsx)(n.li,{children:"Zero real-world training"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Results"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Sim"}),": 100% success rate"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Real"}),": 60% success rate on first try"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"After calibration"}),": 80% success rate"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Lesson"}),": Heavy DR works, but reality gap still exists."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"case-study-2-anymal-quadruped-locomotion",children:"Case Study 2: ANYmal Quadruped Locomotion"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Challenge"}),": Rough terrain walking",(0,s.jsx)(n.br,{}),"\n",(0,s.jsx)(n.strong,{children:"Approach"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"DR on terrain geometry, friction, and slopes"}),"\n",(0,s.jsx)(n.li,{children:"Progressive transfer (sim \u2192 indoor \u2192 outdoor)"}),"\n",(0,s.jsx)(n.li,{children:"System ID for leg dynamics"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Results"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Walked on snow, mud, stairs ",(0,s.jsx)(n.strong,{children:"without real-world training"})]}),"\n",(0,s.jsx)(n.li,{children:"90% success rate on unseen terrains"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Lesson"}),": DR + progressive transfer = robust policies."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"practical-tips-for-reducing-reality-gap",children:"Practical Tips for Reducing Reality Gap"}),"\n",(0,s.jsx)(n.h3,{id:"design-principles",children:"Design Principles"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Start Simple"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Test on flat surfaces before rough terrain"}),"\n",(0,s.jsx)(n.li,{children:"Use simple objects before complex manipulation"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Measure Everything"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Log all sensor data (sim and real)"}),"\n",(0,s.jsx)(n.li,{children:"Compare statistical distributions"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Iterate Quickly"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Short trials (30 seconds) to avoid robot damage"}),"\n",(0,s.jsx)(n.li,{children:"Use safety harnesses during bipedal tests"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Randomize Conservatively"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Start with small randomization ranges"}),"\n",(0,s.jsx)(n.li,{children:"Gradually increase as policies become robust"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Use Real Data When Possible"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Even 10% real data massively helps"}),"\n",(0,s.jsx)(n.li,{children:"Prioritize critical scenarios (e.g., falling)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"debugging-sim-to-real-failures",children:"Debugging Sim-to-Real Failures"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-mermaid",children:"graph TD\r\n    A[Policy Fails on Real Robot] --\x3e B{Where Does It Fail?}\r\n    B --\x3e|Perception| C[Check Sensor Calibration]\r\n    B --\x3e|Action Execution| D[Check Motor Dynamics]\r\n    B --\x3e|State Estimation| E[Check IMU/Encoder Noise]\r\n    \r\n    C --\x3e F[Add Sensor Noise to Sim]\r\n    D --\x3e G[Identify Joint Friction/Damping]\r\n    E --\x3e H[Increase IMU Noise in Sim]\r\n    \r\n    F --\x3e I[Retrain with Updated Sim]\r\n    G --\x3e I\r\n    H --\x3e I\r\n    I --\x3e J[Test Again on Real Robot]\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"complete-example-sim-to-real-bipedal-walking",children:"Complete Example: Sim-to-Real Bipedal Walking"}),"\n",(0,s.jsx)(n.h3,{id:"training-script-with-full-dr",children:"Training Script with Full DR"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'"""\r\nComplete example: Train humanoid walking with DR,\r\ndeploy to real robot\r\n"""\r\nimport numpy as np\r\nimport gymnasium as gym\r\nfrom stable_baselines3 import PPO\r\n\r\nclass HumanoidWalkingEnv(gym.Env):\r\n    def __init__(self, domain_randomization=True):\r\n        super().__init__()\r\n        self.dr_enabled = domain_randomization\r\n        \r\n        # Observation: joint positions, velocities, IMU\r\n        self.observation_space = gym.spaces.Box(\r\n            low=-np.inf, high=np.inf, shape=(30,), dtype=np.float32\r\n        )\r\n        \r\n        # Action: target joint positions\r\n        self.action_space = gym.spaces.Box(\r\n            low=-1, high=1, shape=(12,), dtype=np.float32\r\n        )\r\n    \r\n    def reset(self):\r\n        if self.dr_enabled:\r\n            self.apply_domain_randomization()\r\n        \r\n        self.robot.reset()\r\n        return self.get_observation()\r\n    \r\n    def apply_domain_randomization(self):\r\n        # Physics\r\n        friction = np.random.uniform(0.6, 1.0)\r\n        self.set_ground_friction(friction)\r\n        \r\n        # Mass (\xb110%)\r\n        for link in self.robot.links:\r\n            link.mass *= np.random.uniform(0.9, 1.1)\r\n        \r\n        # Sensor noise\r\n        self.imu_noise_stddev = np.random.uniform(0.01, 0.05)\r\n        \r\n        # Actuator delays\r\n        self.motor_delay = np.random.uniform(0.01, 0.03)  # 10-30ms\r\n        \r\n        # Visual\r\n        self.randomize_lighting()\r\n    \r\n    def step(self, action):\r\n        # Apply action with delay\r\n        delayed_action = self.apply_motor_delay(action, self.motor_delay)\r\n        self.robot.set_joint_targets(delayed_action)\r\n        \r\n        # Sim physics\r\n        self.sim.step()\r\n        \r\n        # Get noisy observation\r\n        obs = self.get_observation()\r\n        obs += np.random.normal(0, self.imu_noise_stddev, obs.shape)\r\n        \r\n        # Calculate reward\r\n        reward = self.calculate_reward()\r\n        \r\n        # Check termination\r\n        done = self.is_fallen() or self.sim.time > 10.0\r\n        \r\n        return obs, reward, done, {}\r\n    \r\n    def calculate_reward(self):\r\n        # Reward forward velocity\r\n        velocity_reward = self.robot.get_base_velocity()[0]  # x-direction\r\n        \r\n        # Penalty for high energy use\r\n        energy_penalty = -0.01 * np.sum(np.abs(self.robot.get_joint_torques()))\r\n        \r\n        # Penalty for falling\r\n        height_penalty = 0 if self.robot.get_base_height() > 0.5 else -10\r\n        \r\n        return velocity_reward + energy_penalty + height_penalty\r\n\r\n# Training\r\nenv = HumanoidWalkingEnv(domain_randomization=True)\r\nmodel = PPO(\r\n    "MlpPolicy",\r\n    env,\r\n    learning_rate=3e-4,\r\n    n_steps=2048,\r\n    batch_size=64,\r\n    verbose=1\r\n)\r\n\r\n# Train for 5M steps (~2-3 hours on GPU)\r\nmodel.learn(total_timesteps=5_000_000)\r\nmodel.save("humanoid_walk_dr")\r\n\r\n# Deployment to real robot\r\nenv_real = HumanoidWalkingEnv(domain_randomization=False)  # No DR on real\r\nobs = env_real.reset()\r\nfor step in range(1000):\r\n    action, _ = model.predict(obs, deterministic=True)\r\n    obs, reward, done, _ = env_real.step(action)\r\n    if done:\r\n        break\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(n.h3,{id:"-key-takeaways",children:"\ud83c\udfaf Key Takeaways"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Reality gap"})," is inevitable but can be minimized"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Domain randomization"})," creates robust policies by training across variations"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"System identification"})," calibrates simulation to match reality"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Progressive transfer"})," (sim \u2192 hybrid \u2192 real) reduces deployment risk"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Validation metrics"})," (success rate, trajectory error) quantify transfer quality"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Real-world data"}),", even small amounts, dramatically improves transfer"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"-sim-to-real-workflow",children:"\ud83d\udd04 Sim-to-Real Workflow"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-mermaid",children:"graph LR\r\n    A[Design in Sim] --\x3e B[Train with DR]\r\n    B --\x3e C[System ID]\r\n    C --\x3e D[Update Sim]\r\n    D --\x3e E[Retrain]\r\n    E --\x3e F[Test on Real]\r\n    F --\x3e G{Success?}\r\n    G --\x3e|No| H[Analyze Failure]\r\n    H --\x3e C\r\n    G --\x3e|Yes| I[Deploy \u2705]\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"hands-on-exercise",children:"Hands-On Exercise"}),"\n",(0,s.jsx)(n.h3,{id:"task-train-and-deploy-robust-controller",children:"Task: Train and Deploy Robust Controller"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Requirements"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Create simple reach task (robot arm touches target)"}),"\n",(0,s.jsx)(n.li,{children:"Implement DR for friction, mass, and sensor noise"}),"\n",(0,s.jsx)(n.li,{children:"Train PPO policy for 100k steps"}),"\n",(0,s.jsx)(n.li,{children:"Validate in 10 test episodes with different randomizations"}),"\n",(0,s.jsx)(n.li,{children:"Measure success rate and average error"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Success Criteria"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Training converges (reward increases monotonically)"}),"\n",(0,s.jsx)(n.li,{children:"Success rate in randomized sim: \u226580%"}),"\n",(0,s.jsx)(n.li,{children:"Average reaching error: <5cm"}),"\n",(0,s.jsx)(n.li,{children:"Policy generalizes to unseen randomizations"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Estimated Time"}),": 45 minutes"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"further-resources",children:"Further Resources"}),"\n",(0,s.jsx)(n.h3,{id:"research-papers",children:"Research Papers"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\ud83d\udcc4 ",(0,s.jsx)(n.a,{href:"https://arxiv.org/abs/1808.00177",children:"OpenAI Dactyl"})," - Rubik's Cube solving with DR"]}),"\n",(0,s.jsxs)(n.li,{children:["\ud83d\udcc4 ",(0,s.jsx)(n.a,{href:"https://arxiv.org/abs/1703.06907",children:"Sim-to-Real via Domain Randomization"})," - Foundational paper"]}),"\n",(0,s.jsxs)(n.li,{children:["\ud83d\udcc4 ",(0,s.jsx)(n.a,{href:"https://arxiv.org/abs/1808.00177",children:"Learning Dexterous In-Hand Manipulation"})," - Advanced DR"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"tools",children:"Tools"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\ud83d\udee0\ufe0f ",(0,s.jsx)(n.a,{href:"https://developer.nvidia.com/isaac-gym",children:"NVIDIA Isaac Gym"})," - GPU-accelerated sim for RL"]}),"\n",(0,s.jsxs)(n.li,{children:["\ud83d\udee0\ufe0f ",(0,s.jsx)(n.a,{href:"https://mujoco.org/",children:"MuJoCo"})," - Fast physics for robotics"]}),"\n",(0,s.jsxs)(n.li,{children:["\ud83d\udee0\ufe0f ",(0,s.jsx)(n.a,{href:"https://pybullet.org/",children:"PyBullet"})," - Open-source physics sim"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"community",children:"Community"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\ud83d\udcac ",(0,s.jsx)(n.a,{href:"https://robotics.stackexchange.com/",children:"Robotics StackExchange"})," - Sim-to-real questions"]}),"\n",(0,s.jsxs)(n.li,{children:["\ud83d\udcac ",(0,s.jsx)(n.a,{href:"https://reddit.com/r/robotics",children:"Reddit r/robotics"})," - Community discussions"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"congratulations-",children:"Congratulations! \ud83c\udf89"}),"\n",(0,s.jsxs)(n.p,{children:["You've completed ",(0,s.jsx)(n.strong,{children:"Module 2: The Digital Twin"}),"!"]}),"\n",(0,s.jsx)(n.h3,{id:"what-youve-learned",children:"What You've Learned:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"\u2705 Simulation fundamentals and digital twins"}),"\n",(0,s.jsx)(n.li,{children:"\u2705 Gazebo for physics-accurate simulation"}),"\n",(0,s.jsx)(n.li,{children:"\u2705 Unity for photorealistic rendering"}),"\n",(0,s.jsx)(n.li,{children:"\u2705 Comprehensive sensor simulation"}),"\n",(0,s.jsx)(n.li,{children:"\u2705 Sim-to-real transfer techniques"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"module-2-summary",children:"Module 2 Summary:"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Chapter"}),(0,s.jsx)(n.th,{children:"Topic"}),(0,s.jsx)(n.th,{children:"Key Skill"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"6"}),(0,s.jsx)(n.td,{children:"Introduction"}),(0,s.jsx)(n.td,{children:"Understanding simulation's role"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"7"}),(0,s.jsx)(n.td,{children:"Gazebo"}),(0,s.jsx)(n.td,{children:"Physics-based robot testing"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"8"}),(0,s.jsx)(n.td,{children:"Unity"}),(0,s.jsx)(n.td,{children:"Photorealistic visualization"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"9"}),(0,s.jsx)(n.td,{children:"Sensors"}),(0,s.jsx)(n.td,{children:"Vision and perception simulation"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"10"}),(0,s.jsx)(n.td,{children:"Sim-to-Real"}),(0,s.jsx)(n.td,{children:"Deploying to real robots"})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"whats-next",children:"What's Next?"}),"\n",(0,s.jsxs)(n.p,{children:["In ",(0,s.jsx)(n.strong,{children:"Module 3: The AI-Robot Brain"}),", you'll master:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"NVIDIA Isaac Sim for GPU-accelerated simulation"}),"\n",(0,s.jsx)(n.li,{children:"Isaac ROS for hardware-accelerated SLAM"}),"\n",(0,s.jsx)(n.li,{children:"Nav2 for autonomous navigation"}),"\n",(0,s.jsx)(n.li,{children:"Synthetic data generation at scale"}),"\n",(0,s.jsx)(n.li,{children:"Deploying AI to Jetson edge devices"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Get ready for the cutting edge of Physical AI!"})," \ud83d\ude80\ud83e\udd16"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.admonition,{title:"Module Completion",type:"note",children:(0,s.jsxs)(n.p,{children:["\u2705 You've completed Module 2: The Digital Twin",(0,s.jsx)(n.br,{}),"\n","\u23f1\ufe0f Total time: ~5 hours",(0,s.jsx)(n.br,{}),"\n","\ud83d\udcca Progress: 2/4 modules complete (50%)\r\nNext: Module 3 - The AI-Robot Brain"]})})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>a,x:()=>t});var i=r(6540);const s={},l=i.createContext(s);function a(e){const n=i.useContext(l);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),i.createElement(l.Provider,{value:n},e.children)}}}]);