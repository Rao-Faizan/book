"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[6972],{4529:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>t,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"module3/chapter13","title":"Chapter 13: Isaac ROS and Hardware-Accelerated SLAM","description":"GPU-accelerated Visual SLAM using Isaac ROS with stereo cameras, depth processing, real-time odometry, and Jetson deployment","source":"@site/docs/module3/chapter13.mdx","sourceDirName":"module3","slug":"/module3/chapter13","permalink":"/book/docs/module3/chapter13","draft":false,"unlisted":false,"editUrl":"https://github.com/Rao-Faizan/book/tree/master/docs/module3/chapter13.mdx","tags":[],"version":"current","sidebarPosition":13,"frontMatter":{"title":"Chapter 13: Isaac ROS and Hardware-Accelerated SLAM","description":"GPU-accelerated Visual SLAM using Isaac ROS with stereo cameras, depth processing, real-time odometry, and Jetson deployment","sidebar_position":13},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 12: Isaac Sim for Photorealistic Simulation","permalink":"/book/docs/module3/chapter12"},"next":{"title":"Chapter 14: Nav2 for Bipedal Navigation","permalink":"/book/docs/module3/chapter14"}}');var i=r(4848),a=r(8453);const l={title:"Chapter 13: Isaac ROS and Hardware-Accelerated SLAM",description:"GPU-accelerated Visual SLAM using Isaac ROS with stereo cameras, depth processing, real-time odometry, and Jetson deployment",sidebar_position:13},t="Chapter 13: Isaac ROS and Hardware-Accelerated SLAM",o={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"What is Isaac ROS?",id:"what-is-isaac-ros",level:2},{value:"Why GPU Acceleration Matters",id:"why-gpu-acceleration-matters",level:3},{value:"Isaac ROS Architecture",id:"isaac-ros-architecture",level:2},{value:"Key Components",id:"key-components",level:3},{value:"Installation",id:"installation",level:2},{value:"System Requirements",id:"system-requirements",level:3},{value:"Method 1: Docker Installation (Recommended)",id:"method-1-docker-installation-recommended",level:3},{value:"Method 2: Native Installation",id:"method-2-native-installation",level:3},{value:"Understanding Visual SLAM",id:"understanding-visual-slam",level:2},{value:"cuVSLAM Algorithm",id:"cuvslam-algorithm",level:3},{value:"Configuring Isaac ROS Visual SLAM",id:"configuring-isaac-ros-visual-slam",level:2},{value:"Camera Setup: Stereo Pair",id:"camera-setup-stereo-pair",level:3},{value:"Launch File Configuration",id:"launch-file-configuration",level:3},{value:"Calibration",id:"calibration",level:3},{value:"GPU-Accelerated Stereo Depth",id:"gpu-accelerated-stereo-depth",level:2},{value:"Stereo Disparity Matching",id:"stereo-disparity-matching",level:3},{value:"Point Cloud Generation",id:"point-cloud-generation",level:3},{value:"Visualizing SLAM in RViz2",id:"visualizing-slam-in-rviz2",level:2},{value:"Complete RViz Configuration",id:"complete-rviz-configuration",level:3},{value:"Save RViz Config",id:"save-rviz-config",level:3},{value:"Performance Benchmarking",id:"performance-benchmarking",level:2},{value:"GPU vs CPU Comparison",id:"gpu-vs-cpu-comparison",level:3},{value:"Deploying to Jetson Orin Nano",id:"deploying-to-jetson-orin-nano",level:2},{value:"JetPack Installation",id:"jetpack-installation",level:3},{value:"Isaac ROS on Jetson",id:"isaac-ros-on-jetson",level:3},{value:"Deploy SLAM Pipeline",id:"deploy-slam-pipeline",level:3},{value:"Integration with Navigation",id:"integration-with-navigation",level:2},{value:"Publishing Odometry to TF",id:"publishing-odometry-to-tf",level:3},{value:"Using SLAM with Nav2",id:"using-slam-with-nav2",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Issue 1: SLAM Not Initializing",id:"issue-1-slam-not-initializing",level:3},{value:"Issue 2: Poor Tracking",id:"issue-2-poor-tracking",level:3},{value:"Issue 3: High Latency",id:"issue-3-high-latency",level:3},{value:"Summary",id:"summary",level:2},{value:"\ud83c\udfaf Key Takeaways",id:"-key-takeaways",level:3},{value:"Hands-On Exercise",id:"hands-on-exercise",level:2},{value:"Task: Deploy Visual SLAM Pipeline",id:"task-deploy-visual-slam-pipeline",level:3},{value:"Further Resources",id:"further-resources",level:2},{value:"Official Documentation",id:"official-documentation",level:3},{value:"Community",id:"community",level:3},{value:"What&#39;s Next?",id:"whats-next",level:2}];function d(e){const n={a:"a",admonition:"admonition",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"chapter-13-isaac-ros-and-hardware-accelerated-slam",children:"Chapter 13: Isaac ROS and Hardware-Accelerated SLAM"})}),"\n",(0,i.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsx)(n.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Install"})," Isaac ROS packages on Ubuntu 22.04 and Jetson"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Understand"})," GX Framework (GXF) for GPU-accelerated pipelines"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Configure"})," Isaac ROS Visual SLAM with stereo cameras"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Process"})," stereo depth images on GPU with TensorRT"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Visualize"})," SLAM output in RViz2 with odometry and maps"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Deploy"})," perception stack to NVIDIA Jetson Orin Nano"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Benchmark"})," GPU vs CPU performance for perception tasks"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Prerequisites"}),": Chapters 11-12 (Isaac ecosystem, ROS 2 knowledge)",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"Hardware"}),": RTX GPU (development), Jetson Orin Nano (deployment)",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"Estimated Time"}),": 90 minutes"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"what-is-isaac-ros",children:"What is Isaac ROS?"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Isaac ROS"})," is a collection of GPU-accelerated ROS 2 packages for robotics perception, built on ",(0,i.jsx)(n.strong,{children:"NVIDIA GXF"})," (Graph Execution Framework)."]}),"\n",(0,i.jsx)(n.h3,{id:"why-gpu-acceleration-matters",children:"Why GPU Acceleration Matters"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"CPU-Based Perception"})," (traditional ROS 2):"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Stereo depth: 5-10 FPS"}),"\n",(0,i.jsx)(n.li,{children:"Object detection: 10-15 FPS"}),"\n",(0,i.jsx)(n.li,{children:"Visual SLAM: 15-20 FPS"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"GPU-Based Perception"})," (Isaac ROS):"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Stereo depth: ",(0,i.jsx)(n.strong,{children:"60+ FPS"})," (12x faster)"]}),"\n",(0,i.jsxs)(n.li,{children:["Object detection: ",(0,i.jsx)(n.strong,{children:"90+ FPS"})," (6x faster)"]}),"\n",(0,i.jsxs)(n.li,{children:["Visual SLAM: ",(0,i.jsx)(n.strong,{children:"120+ FPS"})," (6x faster)"]}),"\n"]}),"\n",(0,i.jsx)(n.admonition,{title:"Real-Time Perception",type:"tip",children:(0,i.jsxs)(n.p,{children:["GPU acceleration enables ",(0,i.jsx)(n.strong,{children:"real-time"})," perception at high frame rates, critical for fast-moving autonomous robots."]})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"isaac-ros-architecture",children:"Isaac ROS Architecture"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-mermaid",children:"graph TD\r\n    A[Camera Data] --\x3e B[Isaac ROS Nodes]\r\n    B --\x3e C[GXF Graph Executor]\r\n    C --\x3e D[GPU Kernels<br/>CUDA/TensorRT]\r\n    D --\x3e E[Processed Output]\r\n    E --\x3e F[ROS 2 Topics]\r\n    \r\n    F --\x3e G[/visual_slam/tracking/odometry]\r\n    F --\x3e H[/depth/image]\r\n    F --\x3e I[/detections]\r\n    \r\n    style D fill:#76B900\r\n    style F fill:#F4A261\n"})}),"\n",(0,i.jsx)(n.h3,{id:"key-components",children:"Key Components"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"GXF (Graph Execution Framework)"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Nvidia's framework for heterogeneous computing"}),"\n",(0,i.jsx)(n.li,{children:'Pipelines with CPU and GPU "codelets"'}),"\n",(0,i.jsx)(n.li,{children:"Optimized scheduling and memory management"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"ROS 2 Bridge"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Converts ROS 2 messages to GXF entities"}),"\n",(0,i.jsx)(n.li,{children:"Zero-copy where possible (reduces latency)"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"GPU-Accelerated Algorithms"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Visual SLAM: cuVSLAM"}),"\n",(0,i.jsx)(n.li,{children:"Stereo Depth: SGM (Semi-Global Matching)"}),"\n",(0,i.jsx)(n.li,{children:"Object Detection: TensorRT-optimized DNNs"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,i.jsx)(n.h3,{id:"system-requirements",children:"System Requirements"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Development Machine"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Ubuntu 22.04 LTS"}),"\n",(0,i.jsx)(n.li,{children:"ROS 2 Humble"}),"\n",(0,i.jsx)(n.li,{children:"NVIDIA RTX GPU (2070+)"}),"\n",(0,i.jsx)(n.li,{children:"CUDA 12.0+"}),"\n",(0,i.jsx)(n.li,{children:"Docker (recommended)"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Deployment Target"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Jetson Orin Nano/NX"}),"\n",(0,i.jsx)(n.li,{children:"JetPack 6.0+"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"method-1-docker-installation-recommended",children:"Method 1: Docker Installation (Recommended)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Install NVIDIA Container Toolkit"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Add NVIDIA Docker repo\r\ndistribution=$(. /etc/os-release;echo $ID$VERSION_ID)\r\ncurl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -\r\ncurl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \\\r\n  sudo tee /etc/apt/sources.list.d/nvidia-docker.list\r\n\r\n# Install\r\nsudo apt-get update\r\nsudo apt-get install -y nvidia-container-toolkit\r\n\r\n# Restart Docker\r\nsudo systemctl restart docker\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Pull Isaac ROS Docker Image"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Clone Isaac ROS common\r\ncd ~/workspaces\r\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_common.git\r\n\r\n# Build and run Docker container\r\ncd isaac_ros_common\r\n./scripts/run_dev.sh ~/workspaces\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Inside Container"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Install Isaac ROS Visual SLAM\r\ncd /workspaces\r\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_visual_slam.git\r\n\r\n# Build\r\ncd /workspaces/isaac_ros_visual_slam\r\ncolcon build --packages-up-to isaac_ros_visual_slam\r\n\r\n# Source\r\nsource install/setup.bash\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"method-2-native-installation",children:"Method 2: Native Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Install dependencies\r\nsudo apt-get install -y \\\r\n  ros-humble-vision-msgs \\\r\n  ros-humble-sensor-msgs \\\r\n  ros-humble-tf2-ros\r\n\r\n# Clone Isaac ROS\r\nmkdir -p ~/ros2_ws/src\r\ncd ~/ros2_ws/src\r\n\r\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_visual_slam.git\r\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_common.git\r\n\r\n# Install rosdep dependencies\r\ncd ~/ros2_ws\r\nrosdep install --from-paths src --ignore-src -r -y\r\n\r\n# Build\r\ncolcon build --packages-select isaac_ros_visual_slam\r\n\r\n# Source\r\nsource install/setup.bash\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"understanding-visual-slam",children:"Understanding Visual SLAM"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Visual SLAM"})," (Simultaneous Localization and Mapping) estimates robot pose while building a map using only camera data."]}),"\n",(0,i.jsx)(n.h3,{id:"cuvslam-algorithm",children:"cuVSLAM Algorithm"}),"\n",(0,i.jsxs)(n.p,{children:["Isaac ROS uses ",(0,i.jsx)(n.strong,{children:"cuVSLAM"})," (CUDA Visual SLAM):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-mermaid",children:"graph LR\r\n    A[Stereo Images] --\x3e B[Feature Extraction<br/>GPU ORB]\r\n    B --\x3e C[Stereo Matching<br/>GPU SGM]\r\n    C --\x3e D[Visual Odometry<br/>GPU PnP]\r\n    D --\x3e E[Loop Closure<br/>GPU DBoW2]\r\n    E --\x3e F[Pose Graph Opt<br/>GPU g2o]\r\n    F --\x3e G[Map + Odometry]\r\n    \r\n    style B fill:#76B900\r\n    style C fill:#76B900\r\n    style D fill:#76B900\r\n    style E fill:#76B900\r\n    style F fill:#76B900\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Advantages"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Entire pipeline on GPU (no CPU/GPU transfers)"}),"\n",(0,i.jsx)(n.li,{children:"120+ FPS on RTX 4070"}),"\n",(0,i.jsx)(n.li,{children:"Low latency (<10ms)"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"configuring-isaac-ros-visual-slam",children:"Configuring Isaac ROS Visual SLAM"}),"\n",(0,i.jsx)(n.h3,{id:"camera-setup-stereo-pair",children:"Camera Setup: Stereo Pair"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Hardware Options"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Intel RealSense D435i"}),": Built-in stereo ($200)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ZED 2"}),": High-quality stereo ($450)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Custom Stereo Rig"}),": Two identical cameras"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Key Parameters"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Baseline"}),": Distance between cameras (wider = better depth range)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Calibration"}),": Intrinsic + extrinsic parameters"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Resolution"}),": 640x480 (balance speed/accuracy)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Frame Rate"}),": 30 FPS minimum"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"launch-file-configuration",children:"Launch File Configuration"}),"\n",(0,i.jsxs)(n.p,{children:["Create ",(0,i.jsx)(n.code,{children:"isaac_slam_stereo.launch.py"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from launch import LaunchDescription\r\nfrom launch_ros.actions import Node\r\nfrom launch.actions import IncludeLaunchDescription\r\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\r\nfrom ament_index_python.packages import get_package_share_directory\r\nimport os\r\n\r\ndef generate_launch_description():\r\n    \r\n    # Launch camera (RealSense example)\r\n    realsense_launch = IncludeLaunchDescription(\r\n        PythonLaunchDescriptionSource([\r\n            os.path.join(\r\n                get_package_share_directory('realsense2_camera'),\r\n                'launch', 'rs_launch.py'\r\n            )\r\n        ]),\r\n        launch_arguments={\r\n            'enable_infra1': 'true',\r\n            'enable_infra2': 'true',\r\n            'enable_depth': 'true',\r\n            'depth_module.profile': '640x480x30'\r\n        }.items()\r\n    )\r\n    \r\n    # Isaac ROS Visual SLAM node\r\n    visual_slam_node = Node(\r\n        package='isaac_ros_visual_slam',\r\n        executable='isaac_ros_visual_slam',\r\n        name='visual_slam',\r\n        parameters=[{\r\n            'denoise_input_images': True,\r\n            'rectified_images': True,\r\n            'enable_debug_mode': False,\r\n            'debug_dump_path': '/tmp/cuvslam',\r\n            'enable_slam_visualization': True,\r\n            'enable_landmarks_view': True,\r\n            'enable_observations_view': True,\r\n            'map_frame': 'map',\r\n            'odom_frame': 'odom',\r\n            'base_frame': 'base_link',\r\n            'input_left_camera_frame': 'camera_infra1_frame',\r\n            'input_right_camera_frame': 'camera_infra2_frame',\r\n            'min_num_images': 30,  # Minimum for initialization\r\n            'img_jitter_threshold_ms': 22.0\r\n        }],\r\n        remappings=[\r\n            ('stereo_camera/left/image', '/camera/infra1/image_rect_raw'),\r\n            ('stereo_camera/left/camera_info', '/camera/infra1/camera_info'),\r\n            ('stereo_camera/right/image', '/camera/infra2/image_rect_raw'),\r\n            ('stereo_camera/right/camera_info', '/camera/infra2/camera_info')\r\n        ]\r\n    )\r\n    \r\n    return LaunchDescription([\r\n        realsense_launch,\r\n        visual_slam_node\r\n    ])\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Launch"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 launch my_isaac_slam isaac_slam_stereo.launch.py\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"calibration",children:"Calibration"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Requirement"}),": Accurate stereo calibration for good depth estimation."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Using camera_calibration package"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Install calibration tool\r\nsudo apt install ros-humble-camera-calibration\r\n\r\n# Run calibration (print checkerboard pattern)\r\nros2 run camera_calibration cameracalibrator \\\r\n  --size 8x6 \\\r\n  --square 0.025 \\\r\n  --ros-args \\\r\n  -r image:=/camera/infra1/image_raw \\\r\n  -r camera:=/camera/infra1\r\n\r\n# Move checkerboard for various poses\r\n# Click "Calibrate" when X,Y,Size,Skew bars fill\r\n# Click "Save" to export calibration\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Result"}),": ",(0,i.jsx)(n.code,{children:"camera_info.yaml"})," with calibration parameters"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"gpu-accelerated-stereo-depth",children:"GPU-Accelerated Stereo Depth"}),"\n",(0,i.jsx)(n.h3,{id:"stereo-disparity-matching",children:"Stereo Disparity Matching"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Semi-Global Matching (SGM)"})," on GPU:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Launch stereo disparity node\r\nfrom launch_ros.actions import Node\r\n\r\ndisparity_node = Node(\r\n    package='isaac_ros_stereo_image_proc',\r\n    executable='disparity_node',\r\n    name='disparity',\r\n    parameters=[{\r\n        'backends': 'CUDA',  # Use GPU\r\n        'window_size': 5,\r\n        'min_disparity': 0,\r\n        'max_disparity': 64,\r\n        'uniqueness_ratio': 15,\r\n        'P1': 8,\r\n        'P2': 109\r\n    }],\r\n    remappings=[\r\n        ('left/image_rect', '/camera/infra1/image_rect_raw'),\r\n        ('left/camera_info', '/camera/infra1/camera_info'),\r\n        ('right/image_rect', '/camera/infra2/image_rect_raw'),\r\n        ('right/camera_info', '/camera/infra2/camera_info')\r\n    ]\r\n)\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Output Topics"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"/disparity"}),": DisparityImage message"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"/depth/image"}),": Float32 depth map (meters)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"/depth/points"}),": PointCloud2"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"point-cloud-generation",children:"Point Cloud Generation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Convert disparity to point cloud\r\nfrom sensor_msgs.msg import PointCloud2\r\nimport rclpy\r\nfrom rclpy.node import Node\r\n\r\nclass DepthToPointCloud(Node):\r\n    def __init__(self):\r\n        super().__init__('depth_to_pointcloud')\r\n        \r\n        self.sub = self.create_subscription(\r\n            DisparityImage,\r\n            '/disparity',\r\n            self.disparity_callback,\r\n            10\r\n        )\r\n        \r\n        self.pub = self.create_publisher(PointCloud2, '/depth/points', 10)\r\n    \r\n    def disparity_callback(self, msg):\r\n        # GPU-accelerated conversion (handled by Isaac ROS)\r\n        # Point cloud automatically published\r\n        pass\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Visualize in RViz2"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"rviz2\r\n# Add PointCloud2 display\r\n# Topic: /depth/points\r\n# Fixed Frame: camera_link\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"visualizing-slam-in-rviz2",children:"Visualizing SLAM in RViz2"}),"\n",(0,i.jsx)(n.h3,{id:"complete-rviz-configuration",children:"Complete RViz Configuration"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Topics to Visualize"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Odometry"})," (",(0,i.jsx)(n.code,{children:"/visual_slam/tracking/odometry"}),"):"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Add \u2192 Odometry"}),"\n",(0,i.jsx)(n.li,{children:"Covariance: Position + Orientation"}),"\n",(0,i.jsx)(n.li,{children:"Keep: 100"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Map Points"})," (",(0,i.jsx)(n.code,{children:"/visual_slam/vis/landmarks_cloud"}),"):"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Add \u2192 PointCloud2"}),"\n",(0,i.jsx)(n.li,{children:"Color: White"}),"\n",(0,i.jsx)(n.li,{children:"Size: 0.02"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Camera Frustum"})," (",(0,i.jsx)(n.code,{children:"/visual_slam/vis/loop_closure_cloud"}),"):"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Add \u2192 Camera"}),"\n",(0,i.jsx)(n.li,{children:"Image Topic: /camera/infra1/image_rect_raw"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"TF Tree"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Add \u2192 TF"}),"\n",(0,i.jsx)(n.li,{children:"Show Names: true"}),"\n",(0,i.jsx)(n.li,{children:"Frames: map, odom, base_link, camera_link"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"save-rviz-config",children:"Save RViz Config"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"# slam_visualization.rviz\r\nPanels:\r\n  - Class: rviz_common/Displays\r\n    \r\nVisualization Manager:\r\n  Global Options:\r\n    Fixed Frame: map\r\n    \r\n  Displays:\r\n    - Class: rviz_default_plugins/Odometry\r\n      Topic: /visual_slam/tracking/odometry\r\n      Keep: 100\r\n      Color: 255; 0; 0\r\n      \r\n    - Class: rviz_default_plugins/PointCloud2\r\n      Topic: /visual_slam/vis/landmarks_cloud\r\n      Size: 0.02\r\n      Color Transformer: FlatColor\r\n      Color: 255; 255; 255\r\n      \r\n    - Class: rviz_default_plugins/TF\r\n      Show Names: true\r\n      Marker Scale: 0.3\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Load"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"rviz2 -d slam_visualization.rviz\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"performance-benchmarking",children:"Performance Benchmarking"}),"\n",(0,i.jsx)(n.h3,{id:"gpu-vs-cpu-comparison",children:"GPU vs CPU Comparison"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Benchmark Script"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import Image\r\nimport time\r\n\r\nclass PerformanceBenchmark(Node):\r\n    def __init__(self):\r\n        super().__init__('perf_benchmark')\r\n        \r\n        self.frame_times = []\r\n        self.last_time = time.time()\r\n        \r\n        self.sub = self.create_subscription(\r\n            Image,\r\n            '/visual_slam/tracking/slam_image',\r\n            self.callback,\r\n            10\r\n        )\r\n        \r\n        self.timer = self.create_timer(5.0, self.report_fps)\r\n    \r\n    def callback(self, msg):\r\n        now = time.time()\r\n        frame_time = now - self.last_time\r\n        self.frame_times.append(frame_time)\r\n        self.last_time = now\r\n    \r\n    def report_fps(self):\r\n        if len(self.frame_times) > 0:\r\n            avg_fps = 1.0 / (sum(self.frame_times) / len(self.frame_times))\r\n            self.get_logger().info(f'Average FPS: {avg_fps:.1f}')\r\n            self.frame_times = []\r\n\r\ndef main():\r\n    rclpy.init()\r\n    node = PerformanceBenchmark()\r\n    rclpy.spin(node)\r\n    \r\nif __name__ == '__main__':\r\n    main()\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Expected Results"}),":"]}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Hardware"}),(0,i.jsx)(n.th,{children:"Visual SLAM FPS"}),(0,i.jsx)(n.th,{children:"Stereo Depth FPS"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"i7-12700 (CPU only)"}),(0,i.jsx)(n.td,{children:"15-20"}),(0,i.jsx)(n.td,{children:"5-10"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"RTX 4070 (GPU)"}),(0,i.jsx)(n.td,{children:"100-120"}),(0,i.jsx)(n.td,{children:"60-90"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Jetson Orin Nano"}),(0,i.jsx)(n.td,{children:"40-60"}),(0,i.jsx)(n.td,{children:"30-45"})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"deploying-to-jetson-orin-nano",children:"Deploying to Jetson Orin Nano"}),"\n",(0,i.jsx)(n.h3,{id:"jetpack-installation",children:"JetPack Installation"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Flash Jetson with JetPack 6.0"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Download SDK Manager: ",(0,i.jsx)(n.a,{href:"https://developer.nvidia.com/sdk-manager",children:"https://developer.nvidia.com/sdk-manager"})]}),"\n",(0,i.jsx)(n.li,{children:"Connect Jetson via USB-C (recovery mode)"}),"\n",(0,i.jsx)(n.li,{children:"Flash JetPack 6.0 with all components"}),"\n",(0,i.jsx)(n.li,{children:"Wait ~30 minutes"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"isaac-ros-on-jetson",children:"Isaac ROS on Jetson"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"On Jetson Device"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Install ROS 2 Humble\r\nsudo apt install software-properties-common\r\nsudo add-apt-repository universe\r\nsudo apt update && sudo apt install curl -y\r\nsudo curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc | \\\r\n  sudo apt-key add -\r\n\r\nsudo sh -c 'echo \"deb [arch=$(dpkg --print-architecture)] \\\r\n  http://packages.ros.org/ros2/ubuntu $(lsb_release -cs) main\" > \\\r\n  /etc/apt/sources.list.d/ros2-latest.list'\r\n\r\nsudo apt update\r\nsudo apt install ros-humble-desktop\r\n\r\n# Clone Isaac ROS\r\nmkdir -p ~/ros2_ws/src\r\ncd ~/ros2_ws/src\r\ngit clone --branch release-3.0 https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_visual_slam.git\r\n\r\n# Build (use swap if low memory)\r\ncd ~/ros2_ws\r\ncolcon build --packages-select isaac_ros_visual_slam --executor sequential\r\n\r\n# Source\r\nsource install/setup.bash\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"deploy-slam-pipeline",children:"Deploy SLAM Pipeline"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Launch on Jetson"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Connect RealSense camera to Jetson USB 3.0\r\n\r\n# Launch SLAM\r\nros2 launch my_package isaac_slam_jetson.launch.py\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Monitor Performance"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Check GPU usage\r\ntegrastats\r\n\r\n# Check topic rates\r\nros2 topic hz /visual_slam/tracking/odometry\r\n\r\n# Expected: 40-60 Hz\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"integration-with-navigation",children:"Integration with Navigation"}),"\n",(0,i.jsx)(n.h3,{id:"publishing-odometry-to-tf",children:"Publishing Odometry to TF"}),"\n",(0,i.jsx)(n.p,{children:"Isaac ROS Visual SLAM automatically publishes TF:"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"TF Tree"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"map\r\n  \u2514\u2500\u2500 odom\r\n       \u2514\u2500\u2500 base_link\r\n            \u2514\u2500\u2500 camera_link\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Verify"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 run tf2_tools view_frames\r\n\r\n# Generates frames.pdf showing TF tree\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"using-slam-with-nav2",children:"Using SLAM with Nav2"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Configuration"})," (in ",(0,i.jsx)(n.code,{children:"nav2_params.yaml"}),"):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'amcl:\r\n  ros__parameters:\r\n    use_sim_time: false\r\n    robot_model_type: "nav2_amcl::OmniMotionModel"\r\n    odom_frame_id: "odom"  # Provided by Visual SLAM\r\n    base_frame_id: "base_link"\r\n    global_frame_id: "map"\r\n    \r\nslam_toolbox:\r\n  ros__parameters:\r\n    odom_frame: odom  # Isaac Visual SLAM provides this\r\n    map_frame: map\r\n    base_frame: base_link\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Launch Nav2 with Isaac SLAM"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Terminal 1: Isaac SLAM\r\nros2 launch my_package isaac_slam.launch.py\r\n\r\n# Terminal 2: Nav2\r\nros2 launch nav2_bringup navigation_launch.py \\\r\n  params_file:=nav2_params.yaml\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,i.jsx)(n.h3,{id:"issue-1-slam-not-initializing",children:"Issue 1: SLAM Not Initializing"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Symptom"}),": ",(0,i.jsx)(n.code,{children:"/visual_slam/status"})," shows ",(0,i.jsx)(n.code,{children:"NOT_INITIALIZED"})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Move camera with translation (not just rotation)"}),"\n",(0,i.jsx)(n.li,{children:"Ensure sufficient visual features (textured environment)"}),"\n",(0,i.jsx)(n.li,{children:"Check min_num_images parameter (reduce to 20 if struggling)"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"issue-2-poor-tracking",children:"Issue 2: Poor Tracking"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Symptom"}),": Frequent tracking losses, jittery odometry"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Improve lighting (avoid over/under exposure)"}),"\n",(0,i.jsx)(n.li,{children:"Reduce motion speed"}),"\n",(0,i.jsx)(n.li,{children:"Increase camera framerate"}),"\n",(0,i.jsxs)(n.li,{children:["Enable ",(0,i.jsx)(n.code,{children:"denoise_input_images: true"})]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"issue-3-high-latency",children:"Issue 3: High Latency"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Check Pipeline Latency"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from diagnostic_msgs.msg import DiagnosticArray\r\n\r\nclass LatencyMonitor(Node):\r\n    def __init__(self):\r\n        super().__init__('latency_monitor')\r\n        self.sub = self.create_subscription(\r\n            DiagnosticArray,\r\n            '/diagnostics',\r\n            self.callback,\r\n            10\r\n        )\r\n    \r\n    def callback(self, msg):\r\n        for status in msg.status:\r\n            if 'visual_slam' in status.name:\r\n                for kv in status.values:\r\n                    if kv.key == 'latency_ms':\r\n                        self.get_logger().info(f'SLAM latency: {kv.value} ms')\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Target"}),": <20ms on RTX GPU, <50ms on Jetson"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(n.h3,{id:"-key-takeaways",children:"\ud83c\udfaf Key Takeaways"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Isaac ROS"})," provides GPU-accelerated perception for ROS 2"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"cuVSLAM"})," achieves 100+ FPS Visual SLAM on RTX GPUs"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"GXF"})," framework enables heterogeneous CPU/GPU pipelines"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Stereo depth"})," processes at 60+ FPS on GPU vs 5-10 FPS on CPU"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Jetson deployment"})," brings GPU acceleration to robot edge devices"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"RViz2 visualization"})," shows odometry, map points, and TF tree"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Nav2 integration"})," uses SLAM odometry for autonomous navigation"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"hands-on-exercise",children:"Hands-On Exercise"}),"\n",(0,i.jsx)(n.h3,{id:"task-deploy-visual-slam-pipeline",children:"Task: Deploy Visual SLAM Pipeline"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Requirements"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Set up Isaac ROS Visual SLAM with RealSense D435i"}),"\n",(0,i.jsx)(n.li,{children:"Configure launch file with proper camera remappings"}),"\n",(0,i.jsx)(n.li,{children:"Calibrate stereo camera"}),"\n",(0,i.jsx)(n.li,{children:"Run SLAM and walk robot/camera through environment"}),"\n",(0,i.jsx)(n.li,{children:"Visualize in RViz2 (odometry + map points)"}),"\n",(0,i.jsx)(n.li,{children:"Benchmark FPS on your GPU"}),"\n",(0,i.jsx)(n.li,{children:"(Optional) Deploy to Jetson Orin Nano"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Success Criteria"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"SLAM initializes within 10 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Odometry published at >30 Hz"}),"\n",(0,i.jsx)(n.li,{children:"Map contains 1000+ landmark points"}),"\n",(0,i.jsx)(n.li,{children:"No tracking losses during 2-minute test"}),"\n",(0,i.jsx)(n.li,{children:"RViz shows consistent TF tree"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Estimated Time"}),": 75 minutes"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"further-resources",children:"Further Resources"}),"\n",(0,i.jsx)(n.h3,{id:"official-documentation",children:"Official Documentation"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\ud83d\udcd8 ",(0,i.jsx)(n.a,{href:"https://nvidia-isaac-ros.github.io/",children:"Isaac ROS Docs"})," - Complete API reference"]}),"\n",(0,i.jsxs)(n.li,{children:["\ud83c\udfa5 ",(0,i.jsx)(n.a,{href:"https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_visual_slam/blob/main/README.md",children:"Isaac ROS Tutorials"})," - Examples"]}),"\n",(0,i.jsxs)(n.li,{children:["\ud83d\udd27 ",(0,i.jsx)(n.a,{href:"https://docs.nvidia.com/metropolis/deepstream/dev-guide/graphtools-docs/docs/text/GraphComposer.html",children:"GXF Documentation"})," - Advanced"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"community",children:"Community"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\ud83d\udcac ",(0,i.jsx)(n.a,{href:"https://forums.developer.nvidia.com/c/isaac-ros/69",children:"NVIDIA Forums - Isaac ROS"})," - Support"]}),"\n",(0,i.jsxs)(n.li,{children:["\ud83d\udcac ",(0,i.jsx)(n.a,{href:"https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_visual_slam/issues",children:"GitHub Issues"})," - Bug reports"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"whats-next",children:"What's Next?"}),"\n",(0,i.jsxs)(n.p,{children:["In ",(0,i.jsx)(n.strong,{children:"Chapter 14"}),", you'll configure ",(0,i.jsx)(n.strong,{children:"Nav2 for Bipedal Navigation"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Nav2 architecture for humanoid footstep planning"}),"\n",(0,i.jsx)(n.li,{children:"Costmap configuration for bipedal footprint"}),"\n",(0,i.jsx)(n.li,{children:"Behavior trees for walking behaviors"}),"\n",(0,i.jsx)(n.li,{children:"Recovery behaviors for legged robots"}),"\n",(0,i.jsx)(n.li,{children:"Integration with Isaac ROS Visual SLAM"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Get ready to make your humanoid navigate autonomously!"})," \ud83d\ude80\ud83e\uddbf"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.admonition,{title:"Chapter Completion",type:"note",children:(0,i.jsxs)(n.p,{children:["\u2705 You've completed Chapter 13: Isaac ROS and Hardware-Accelerated SLAM",(0,i.jsx)(n.br,{}),"\n","\u23f1\ufe0f Estimated time to complete: 90 minutes",(0,i.jsx)(n.br,{}),"\n","\ud83d\udcca Progress: Module 3 - Chapter 3 of 5"]})})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>l,x:()=>t});var s=r(6540);const i={},a=s.createContext(i);function l(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);