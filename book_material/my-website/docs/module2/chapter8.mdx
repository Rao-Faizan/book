---
title: "Chapter 8: Unity for High-Fidelity Rendering"
description: "Create photorealistic robot simulations with Unity, Unity Robotics Hub, and ROS 2 integration for computer vision and HRI"
sidebar_position: 8
---

# Chapter 8: Unity for High-Fidelity Rendering

## Learning Objectives

By the end of this chapter, you will be able to:

- **Install** Unity Hub and Unity Editor (LTS version)
- **Set up** Unity Robotics Hub for ROS 2 integration
- **Import** URDF robot models into Unity using URDF Importer
- **Create** photorealistic indoor/outdoor environments
- **Configure** HDRP (High Definition Render Pipeline) for realistic lighting
- **Establish** bidirectional ROS 2 communication via ROS-TCP-Connector
- **Generate** synthetic training data for computer vision

**Prerequisites**: Chapter 6-7 (Simulation fundamentals, Gazebo), Module 1 (ROS 2, URDF)  
**Estimated Time**: 90 minutes

---

## Why Unity for Robotics?

While Gazebo excels at **physics accuracy**, Unity brings **visual fidelity** to the table. Unity is a professional game engine adapted for robotics simulation.

### Unity's Strengths for Robotics

| Feature | Benefit for Robotics |
|---------|---------------------|
| **Photorealistic Rendering** | Train computer vision models with realistic lighting/textures |
| **HDRP/URP Pipelines** | Ray-traced lighting, global illumination |
| **Asset Ecosystem** | 100,000+ pre-made 3D models (furniture, buildings, characters) |
| **Visual Editor** | Drag-and-drop scene building (no XML coding!) |
| **Cross-Platform** | Same code runs on Windows, Linux, macOS |
| **ML-Agents** | Reinforcement learning toolkit included |
| **Perception Package** | Built-in tool for synthetic data generation |

:::tip When to Use Unity Over Gazebo
- üé® **Computer vision training**: Need photorealistic images
- üë• **Human-robot interaction**: Realistic human characters and animations
- üìä **Synthetic data generation**: Large-scale annotated datasets
- üé¨ **Demonstrations/Marketing**: Beautiful renders for presentations
:::

---

## Installation Guide

### Step 1: Install Unity Hub

Unity Hub is the central manager for Unity Editor versions and projects.

**Windows/Linux:**

```bash
# Download Unity Hub
# Visit: https://unity.com/download

# For Linux (Ubuntu):
wget https://public-cdn.cloud.unity3d.com/hub/prod/UnityHub.AppImage
chmod +x UnityHub.AppImage
./UnityHub.AppImage
```

**First Launch:**
1. Create Unity account (free for students/personal use)
2. Activate Unity Personal license (free, no credit card needed)

---

### Step 2: Install Unity Editor LTS

We'll use **Unity 2022.3 LTS** (Long-Term Support) for stability.

**In Unity Hub:**
1. Click **"Installs"** tab
2. Click **"Install Editor"**
3. Select **"2022.3.x LTS"** (latest patch version)
4. Add modules:
   - ‚úÖ Linux Build Support (if on Windows)
   - ‚úÖ Documentation
   - ‚úÖ Visual Studio Code Editor (recommended)

**Total Download**: ~5-7 GB  
**Installation Time**: 15-30 minutes

:::warning GPU Requirements
Unity HDRP requires:
- **NVIDIA RTX GPU** (2060 or better) for ray tracing
- **12GB+ VRAM** recommended for complex scenes
- Fallback: Use **URP** (Universal Render Pipeline) for lower-end hardware
:::

---

### Step 3: Install Unity Robotics Hub Packages

Create a new Unity project first:

**In Unity Hub:**
1. Click **"Projects"** ‚Üí **"New Project"**
2. Select **"3D (URP)"** template
3. Name: `RoboticsSimulation`
4. Click **"Create Project"**

**Install Robotics Packages:**

Unity will open. Now install packages via Package Manager:

```
Window ‚Üí Package Manager ‚Üí + (top-left) ‚Üí Add package from git URL
```

Add these packages **one by one**:

```
https://github.com/Unity-Technologies/ROS-TCP-Connector.git?path=/com.unity.robotics.ros-tcp-connector
https://github.com/Unity-Technologies/URDF-Importer.git?path=/com.unity.robotics.urdf-importer
https://github.com/Unity-Technologies/Visualizations.git?path=/com.unity.robotics.visualizations
```

**Verify Installation:**

Check `Window ‚Üí Robotics` menu appears with:
- ROS Settings
- URDF Importer

---

### Step 4: Install ROS 2 Side (ROS-TCP-Endpoint)

Back on Ubuntu with ROS 2:

```bash
# Navigate to your ROS 2 workspace
cd ~/ros2_ws/src

# Clone ROS-TCP-Endpoint
git clone https://github.com/Unity-Technologies/ROS-TCP-Endpoint.git

# Install dependencies
cd ~/ros2_ws
rosdep install --from-paths src --ignore-src -r -y

# Build
colcon build --packages-select ros_tcp_endpoint

# Source workspace
source install/setup.bash
```

---

## Unity-ROS 2 Communication Architecture

```mermaid
graph LR
    A[Unity Scene] --> B[ROS-TCP-Connector]
    B --> C[TCP Socket :10000]
    C --> D[ROS-TCP-Endpoint]
    D --> E[ROS 2 Node]
    E --> F[/cmd_vel Topic]
    F --> E
    E --> D
    D --> C
    C --> B
    B --> A
    
    style A fill:#95C8D8
    style E fill:#F4A261
```

**Key Components:**

1. **Unity Side**: `ROS-TCP-Connector` (Unity package)
2. **ROS 2 Side**: `ros_tcp_endpoint` (Python node)
3. **Communication**: TCP socket (default port 10000)
4. **Message Types**: Serialized JSON (automatic conversion)

---

## Configuring ROS Settings in Unity

### Step 1: Set ROS IP Address

In Unity Editor:

```
Robotics ‚Üí ROS Settings
```

Configure:
- **Protocol**: ROS 2
- **ROS IP Address**: `127.0.0.1` (if Unity and ROS on same machine)
  - Or: ROS machine's IP (e.g., `192.168.1.100`)
- **ROS Port**: `10000` (default)
- **Serializer**: `MessageGeneration` (auto-generates C# classes)

**Save Settings**

---

### Step 2: Start ROS-TCP-Endpoint

In Ubuntu terminal:

```bash
source ~/ros2_ws/install/setup.bash

# Launch the endpoint
ros2 run ros_tcp_endpoint default_server_endpoint --ros-args -p ROS_IP:=0.0.0.0
```

**Expected Output:**
```
[INFO] [ros_tcp_endpoint]: ROS-TCP Endpoint starting on 0.0.0.0:10000
[INFO] [ros_tcp_endpoint]: Waiting for Unity connection...
```

---

### Step 3: Test Connection

In Unity, create a test script:

**Create**: `Assets/Scripts/ROSConnectionTest.cs`

```csharp
using UnityEngine;
using Unity.Robotics.ROSTCPConnector;
using RosMessageTypes.Std;

public class ROSConnectionTest : MonoBehaviour
{
    ROSConnection ros;
    
    void Start()
    {
        // Get ROS connection instance
        ros = ROSConnection.GetOrCreateInstance();
        ros.RegisterPublisher<StringMsg>("unity_test");
        
        Debug.Log("ROS Connection Initialized!");
        
        // Send test message every second
        InvokeRepeating("SendTestMessage", 1f, 1f);
    }
    
    void SendTestMessage()
    {
        StringMsg msg = new StringMsg("Hello from Unity!");
        ros.Publish("unity_test", msg);
        Debug.Log("Published message to ROS 2");
    }
}
```

**Attach to GameObject:**
1. Create empty GameObject (`GameObject ‚Üí Create Empty`)
2. Add script component
3. Press **Play**

**Verify in ROS 2:**

```bash
ros2 topic echo /unity_test
```

Should see: `data: 'Hello from Unity!'` üéâ

---

## Importing URDF Robots into Unity

### Method 1: Via URDF Importer (Recommended)

**In Unity:**

```
Robotics ‚Üí Import URDF ‚Üí [Select URDF File]
```

**Settings:**
- **Import Type**: `Runtime`
- **Mesh Decomposer**: `VHACD` (for collision)
- **Axis Type**: `Y-Axis Up` (Unity convention)

**Common Issues & Fixes:**

| Issue | Solution |
|-------|----------|
| Robot invisible | Check material imports, add default material |
| Joints don't move | Ensure `ArticulationBody` components present |
| Wrong orientation | Change axis type to `Z-Axis Up` |
| Meshes missing | Verify mesh file paths in URDF are relative |

---

### Method 2: Programmatic Import

```csharp
using Unity.Robotics.UrdfImporter;

public class RobotSpawner : MonoBehaviour
{
    public string urdfPath = "Assets/URDF/humanoid.urdf";
    
    void Start()
    {
        // Import URDF at runtime
        GameObject robot = UrdfRobotExtensions.Create(urdfPath);
        robot.transform.position = new Vector3(0, 1, 0);
        
        Debug.Log($"Spawned robot: {robot.name}");
    }
}
```

---

### Articulation Body Overview

Unity uses `ArticulationBody` (Unity's physics component for robots) instead of `Rigidbody`.

**Key Differences:**

| Component | Use Case | DOF Limit |
|-----------|----------|-----------|
| **Rigidbody** | Simple objects | 6 DOF (free) |
| **ArticulationBody** | Robot joints | Configurable (revolute, prismatic) |

**Joint Types:**
- `ArticulationJointType.RevoluteJoint`: Rotation (like elbow)
- `ArticulationJointType.PrismaticJoint`: Linear (like slider)
- `ArticulationJointType.FixedJoint`: No movement
- `ArticulationJointType.SphericalJoint`: Ball joint (3 DOF)

---

## Creating a Photorealistic Indoor Environment

### Step 1: Scene Setup

**Create New Scene:**
```
File ‚Üí New Scene ‚Üí Basic (Built-In) ‚Üí Save as "RobotWarehouse"
```

---

### Step 2: Add Ground Plane

```
GameObject ‚Üí 3D Object ‚Üí Plane
```

**Configure:**
- Scale: `(10, 1, 10)` ‚Üí 100m¬≤ floor
- Position: `(0, 0, 0)`

**Add Material:**
1. `Assets ‚Üí Create ‚Üí Material` ‚Üí Name: `FloorMaterial`
2. Drag marble texture to `Base Map`
3. Set `Metallic`: 0.1, `Smoothness`: 0.7
4. Apply to Plane

---

### Step 3: Add Walls (Modular Approach)

```csharp
// Script to generate walls
public class WallBuilder : MonoBehaviour
{
    public GameObject wallPrefab;
    
    void Start()
    {
        // Front wall
        CreateWall(new Vector3(0, 1.5f, 5), new Vector3(10, 3, 0.2f));
        // Back wall
        CreateWall(new Vector3(0, 1.5f, -5), new Vector3(10, 3, 0.2f));
        // Left wall
        CreateWall(new Vector3(-5, 1.5f, 0), new Vector3(0.2f, 3, 10));
        // Right wall
        CreateWall(new Vector3(5, 1.5f, 0), new Vector3(0.2f, 3, 10));
    }
    
    void CreateWall(Vector3 position, Vector3 scale)
    {
        GameObject wall = GameObject.CreatePrimitive(PrimitiveType.Cube);
        wall.transform.position = position;
        wall.transform.localScale = scale;
        wall.GetComponent<Renderer>().material = Resources.Load<Material>("WallMaterial");
    }
}
```

**Or Use Unity Asset Store**:
- Search: "Office Interior" or "Warehouse"
- Import free assets (many available!)

---

### Step 4: Advanced Lighting with HDRP

**Upgrade to HDRP** (if not already):

```
Window ‚Üí Rendering ‚Üí Render Pipeline Converter
Select: Built-In to HDRP
```

**Add Global Volume:**

```
GameObject ‚Üí Volume ‚Üí Global Volume
```

**In Volume Profile:**
- ‚úÖ Enable `Ambient Occlusion` (realistic shadows in corners)
- ‚úÖ Enable `Screen Space Reflections` (mirror-like surfaces)
- ‚úÖ Enable `Indirect Lighting Controller`

**Add Directional Light (Sun):**

```
GameObject ‚Üí Light ‚Üí Directional Light
```

Settings:
- **Intensity**: 50,000 Lux (outdoor) or 500 Lux (indoor)
- **Color Temperature**: 6500K (daylight) or 3000K (warm indoor)
- **Shadows**: Soft Shadows

**Add Point Lights (Indoor Lamps):**

```
GameObject ‚Üí Light ‚Üí Point Light (x4, in corners)
```

Settings per light:
- **Intensity**: 500 Lumens
- **Range**: 10m
- **Color**: Warm white `(255, 240, 220)`

---

### Step 5: Realistic Materials

**PBR (Physically Based Rendering) Workflow:**

For each material:
1. **Albedo Map**: Base color texture
2. **Normal Map**: Surface details (bumps)
3. **Metallic Map**: Which parts are metal (0=plastic, 1=metal)
4. **Roughness Map**: Surface smoothness (0=mirror, 1=rough)

**Example: Metal Table**

```csharp
Material tableMaterial = new Material(Shader.Find("HDRP/Lit"));
tableMaterial.SetTexture("_BaseColorMap", albedoTexture);
tableMaterial.SetTexture("_NormalMap", normalTexture);
tableMaterial.SetFloat("_Metallic", 0.9f);  // Very metallic
tableMaterial.SetFloat("_Smoothness", 0.7f);  // Slightly rough
```

:::tip Free PBR Textures
- **Poly Haven**: https://polyhaven.com/ (CC0 license)
- **Texture Haven**: High-quality materials
- **Unity Asset Store**: Search "PBR"
:::

---

## ROS 2 Message Integration

### Publishing from Unity to ROS 2

**Example: Send Robot Position**

```csharp
using Unity.Robotics.ROSTCPConnector;
using RosMessageTypes.Geometry;

public class RobotPositionPublisher : MonoBehaviour
{
    ROSConnection ros;
    public Transform robotTransform;
    public float publishRate = 10f; // Hz
    
    void Start()
    {
        ros = ROSConnection.GetOrCreateInstance();
        ros.RegisterPublisher<PoseMsg>("robot_pose");
        
        InvokeRepeating("PublishPose", 0f, 1f / publishRate);
    }
    
    void PublishPose()
    {
        PoseMsg msg = new PoseMsg
        {
            position = new PointMsg
            {
                x = robotTransform.position.x,
                y = robotTransform.position.z,  // Unity Y = ROS Z
                z = robotTransform.position.y   // Unity Z = ROS Y
            },
            orientation = new QuaternionMsg
            {
                x = robotTransform.rotation.x,
                y = robotTransform.rotation.z,
                z = robotTransform.rotation.y,
                w = robotTransform.rotation.w
            }
        };
        
        ros.Publish("robot_pose", msg);
    }
}
```

:::warning Unity ‚Üî ROS Coordinate Systems
- **Unity**: Y-up, left-handed
- **ROS**: Z-up, right-handed

**Conversion**:
```
Unity (x, y, z) ‚Üí ROS (x, z, y)
```
:::

---

### Subscribing in Unity to ROS 2

**Example: Receive Velocity Commands**

```csharp
using RosMessageTypes.Geometry;

public class VelocitySubscriber : MonoBehaviour
{
    ROSConnection ros;
    public ArticulationBody robotBase;
    
    void Start()
    {
        ros = ROSConnection.GetOrCreateInstance();
        ros.Subscribe<TwistMsg>("cmd_vel", ApplyVelocity);
    }
    
    void ApplyVelocity(TwistMsg msg)
    {
        // Apply linear velocity
        Vector3 linearVel = new Vector3(
            (float)msg.linear.x,
            0,
            (float)msg.linear.y
        );
        
        robotBase.velocity = linearVel;
        
        // Apply angular velocity
        robotBase.angularVelocity = new Vector3(
            0,
            (float)msg.angular.z,
            0
        );
        
        Debug.Log($"Applied velocity: {linearVel}");
    }
}
```

**Test from ROS 2:**

```bash
ros2 topic pub /cmd_vel geometry_msgs/msg/Twist \
  "{linear: {x: 0.5, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: 0.1}}"
```

Robot should move in Unity! üöÄ

---

## Controlling Robot Joints in Unity

### Method 1: Direct Articulation Drive

```csharp
public class JointController : MonoBehaviour
{
    public ArticulationBody shoulderJoint;
    
    void Update()
    {
        // Get current drive
        var drive = shoulderJoint.xDrive;
        
        // Set target angle (in degrees)
        drive.target = Mathf.Sin(Time.time) * 45f;  // Oscillate ¬±45¬∞
        
        // Configure PID gains
        drive.stiffness = 10000f;  // P gain
        drive.damping = 100f;      // D gain
        drive.forceLimit = 1000f;  // Max torque
        
        // Apply drive
        shoulderJoint.xDrive = drive;
    }
}
```

---

### Method 2: Via ROS 2 Joint Commands

**Unity Subscriber:**

```csharp
using RosMessageTypes.Sensor;

public class JointCommandSubscriber : MonoBehaviour
{
    ROSConnection ros;
    public ArticulationBody[] joints;
    
    void Start()
    {
        ros = ROSConnection.GetOrCreateInstance();
        ros.Subscribe<JointStateMsg>("joint_commands", ApplyJointCommands);
    }
    
    void ApplyJointCommands(JointStateMsg msg)
    {
        for (int i = 0; i < msg.position.Length && i < joints.Length; i++)
        {
            var drive = joints[i].xDrive;
            drive.target = (float)msg.position[i] * Mathf.Rad2Deg;  // Rad ‚Üí Deg
            joints[i].xDrive = drive;
        }
    }
}
```

**Publish from ROS 2:**

```python
from sensor_msgs.msg import JointState

joint_pub = node.create_publisher(JointState, 'joint_commands', 10)

msg = JointState()
msg.name = ['shoulder_joint', 'elbow_joint']
msg.position = [0.5, 1.2]  # Radians
joint_pub.publish(msg)
```

---

## Synthetic Data Generation with Perception Package

Unity's **Perception Package** automates dataset creation for computer vision.

### Installation

```
Window ‚Üí Package Manager ‚Üí + ‚Üí Add from git URL:
https://github.com/Unity-Technologies/com.unity.perception.git
```

---

### Setting Up Perception Camera

**Add to Camera:**

```csharp
using UnityEngine.Perception.GroundTruth;

public class PerceptionSetup : MonoBehaviour
{
    void Start()
    {
        Camera cam = GetComponent<Camera>();
        
        // Add Perception Camera component
        PerceptionCamera perceptionCam = cam.gameObject.AddComponent<PerceptionCamera>();
        
        // Enable bounding box labeling
        BoundingBox2DLabeler labeler = new BoundingBox2DLabeler();
        perceptionCam.AddLabeler(labeler);
        
        Debug.Log("Perception camera ready!");
    }
}
```

---

### Labeling Objects

**Tag objects for detection:**

1. Select robot/object in scene
2. `Inspector ‚Üí Add Component ‚Üí Labeling`
3. Add label: "humanoid", "table", "chair", etc.

---

### Randomization Script

```csharp
using UnityEngine.Perception.Randomization.Scenarios;
using UnityEngine.Perception.Randomization.Randomizers;

public class DataGenerationScenario : PerceptionScenario
{
    public int totalFrames = 1000;
    
    void Start()
    {
        // Add randomizers
        var lightRandomizer = AddRandomizer<LightRandomizer>();
        var textureRandomizer = AddRandomizer<TextureRandomizer>();
        var positionRandomizer = AddRandomizer<PositionRandomizer>();
        
        // Configure
        lightRandomizer.intensityRange = new FloatParameter(500, 50000);
        
        Debug.Log($"Generating {totalFrames} frames...");
    }
}
```

**Output**: Automatically saves to `<Project>/PerceptionOutput/`:
- RGB images
- Bounding box annotations (COCO format)
- Segmentation masks
- Depth maps

---

## Complete Example: Indoor Navigation Scene

**Scenario**: Humanoid robot navigates office with ROS 2 Nav2 integration.

### Unity Scene Hierarchy

```
Scene "OfficeNavigation"
‚îú‚îÄ‚îÄ Environment
‚îÇ   ‚îú‚îÄ‚îÄ Floor (Plane + Material)
‚îÇ   ‚îú‚îÄ‚îÄ Walls (x4 Cubes)
‚îÇ   ‚îú‚îÄ‚îÄ Furniture (Tables, Chairs from Asset Store)
‚îÇ   ‚îî‚îÄ‚îÄ Lighting (Directional + 4 Point Lights)
‚îú‚îÄ‚îÄ Robot
‚îÇ   ‚îú‚îÄ‚îÄ Humanoid (Imported URDF)
‚îÇ   ‚îú‚îÄ‚îÄ Camera (with Perception)
‚îÇ   ‚îî‚îÄ‚îÄ Sensors (Simulated LiDAR - next chapter)
‚îú‚îÄ‚îÄ ROS Integration
‚îÇ   ‚îú‚îÄ‚îÄ ROSConnectionManager (Empty GameObject + Script)
‚îÇ   ‚îú‚îÄ‚îÄ VelocitySubscriber (on Robot)
‚îÇ   ‚îî‚îÄ‚îÄ PosePublisher (on Robot)
‚îî‚îÄ‚îÄ UI
    ‚îî‚îÄ‚îÄ Canvas (Debug info display)
```

---

### Complete Integration Script

```csharp
using UnityEngine;
using Unity.Robotics.ROSTCPConnector;
using RosMessageTypes.Geometry;
using RosMessageTypes.Nav;

public class NavigationIntegration : MonoBehaviour
{
    ROSConnection ros;
    public Transform robot;
    public Camera robotCamera;
    
    void Start()
    {
        // Initialize ROS
        ros = ROSConnection.GetOrCreateInstance();
        ros.RegisterPublisher<PoseStampedMsg>("robot_pose");
        ros.Subscribe<TwistMsg>("cmd_vel", OnVelocityCommand);
        
        Debug.Log("Navigation integration active!");
    }
    
    void Update()
    {
        // Publish pose at 30Hz
        if (Time.frameCount % 2 == 0)
        {
            PublishPose();
        }
    }
    
    void PublishPose()
    {
        PoseStampedMsg msg = new PoseStampedMsg
        {
            header = new HeaderMsg { frame_id = "map" },
            pose = new PoseMsg
            {
                position = ToROSPosition(robot.position),
                orientation = ToROSQuaternion(robot.rotation)
            }
        };
        
        ros.Publish("robot_pose", msg);
    }
    
    void OnVelocityCommand(TwistMsg twist)
    {
        // Apply to robot (simplified)
        Vector3 velocity = new Vector3(
            (float)twist.linear.x,
            0,
            (float)twist.linear.y
        ) * Time.deltaTime;
        
        robot.Translate(velocity, Space.World);
        robot.Rotate(0, (float)twist.angular.z * Mathf.Rad2Deg * Time.deltaTime, 0);
    }
    
    PointMsg ToROSPosition(Vector3 unityPos)
    {
        return new PointMsg
        {
            x = unityPos.x,
            y = unityPos.z,  // Unity Y ‚Üí ROS Z
            z = unityPos.y   // Unity Z ‚Üí ROS Y
        };
    }
    
    QuaternionMsg ToROSQuaternion(Quaternion unityRot)
    {
        return new QuaternionMsg
        {
            x = unityRot.x,
            y = unityRot.z,
            z = unityRot.y,
            w = unityRot.w
        };
    }
}
```

---

## Performance Optimization for Unity Simulations

### Rendering Optimization

```csharp
// Reduce quality for faster simulation
QualitySettings.SetQualityLevel(2);  // Medium quality
Application.targetFrameRate = 30;     // Cap at 30 FPS

// Disable V-Sync
QualitySettings.vSyncCount = 0;
```

---

### Physics Optimization

```
Edit ‚Üí Project Settings ‚Üí Physics
```

- **Fixed Timestep**: 0.02 (50 Hz, down from 100 Hz)
- **Solver Iterations**: 6 (down from 15)
- **Solver Velocity Iterations**: 1 (down from 8)

---

## Troubleshooting

### Issue 1: ROS Connection Timeout

**Symptom**: Unity can't connect to ROS-TCP-Endpoint

**Solutions**:
```bash
# Check ROS endpoint is running
ros2 node list | grep tcp_endpoint

# Check firewall (Ubuntu)
sudo ufw allow 10000/tcp

# Verify IP address
hostname -I
```

---

### Issue 2: Robot Joints Exploding

**Symptom**: ArticulationBody goes haywire, joints fly apart

**Fix**:
- Reduce `stiffness` (try 1000 instead of 10000)
- Increase `damping` (try 500)
- Reduce `forceLimit` (try 100)
- Check mass distribution (parent should be heavier than children)

---

### Issue 3: Poor Frame Rate

**Symptom**: \<20 FPS in Unity Editor

**Solutions**:
1. Switch from HDRP to URP
2. Reduce shadow quality
3. Use LOD (Level of Detail) for meshes
4. Disable anti-aliasing
5. Use occlusion culling

---

## Summary

### üéØ Key Takeaways

- **Unity excels at visual fidelity** for computer vision and HRI scenarios
- **ROS-TCP-Connector** enables bidirectional ROS 2 communication over TCP
- **URDF Importer** converts URDF models to Unity ArticulationBody hierarchy
- **HDRP lighting** creates photorealistic renders with ray tracing
- **Perception Package** automates synthetic data generation with annotations
- **Coordinate system conversion** is critical (Unity Y-up ‚Üî ROS Z-up)

### üìö Unity vs Gazebo Summary

| Aspect | **Gazebo** | **Unity** |
|--------|-----------|----------|
| **Physics** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| **Graphics** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **ROS Integration** | Native | TCP Bridge |
| **Learning Curve** | Medium | Medium-High |
| **Asset Ecosystem** | Small | Massive |
| **Best For** | Control/SLAM | Vision/HRI |

---

## Hands-On Exercise

### Task: Create Photorealistic Robot Scene

**Requirements**:
1. Import your humanoid URDF from Module 1
2. Create indoor environment (10x10m room with walls)
3. Add realistic lighting (1 directional + 4 point lights)
4. Apply PBR materials to floor and walls
5. Establish ROS 2 connection
6. Publish robot pose at 10 Hz
7. Subscribe to `/cmd_vel` and move robot

**Success Criteria**:
- Scene renders at >30 FPS
- ROS 2 topics visible in `ros2 topic list`
- Robot responds to velocity commands
- Materials have normal maps and appropriate metallic/roughness values

**Estimated Time**: 45 minutes

---

## Further Resources

### Official Documentation
- üìò [Unity Robotics Hub](https://github.com/Unity-Technologies/Unity-Robotics-Hub) - Complete tutorials
- üîå [ROS-TCP-Connector Docs](https://github.com/Unity-Technologies/ROS-TCP-Connector) - API reference
- üé® [HDRP Documentation](https://docs.unity3d.com/Packages/com.unity.render-pipelines.high-definition@latest) - Lighting guide

### Video Tutorials
- üé• [Unity Robotics Tutorial Series](https://www.youtube.com/playlist?list=PLQMQNmwN3FvzVl4Fg8zFlpPpZVVWYvfz-) - Official Unity
- üé• [URDF Import Walkthrough](https://www.youtube.com/watch?v=<example>) - Step-by-step

### Community
- üí¨ [Unity Robotics Discord](https://discord.gg/unity-robotics) - Active community
- üí¨ [ROS Discourse - Unity](https://discourse.ros.org/tag/unity) - Integration questions

---

## What's Next?

In **Chapter 9**, you'll master **Sensor Simulation**:
- Simulating RGB cameras, depth cameras, and LiDAR in both Gazebo and Unity
- Adding realistic sensor noise models
- Integrating IMU and force-torque sensors
- Visualizing point clouds in RViz2
- Setting up complete perception pipelines

Get ready to give your robots **eyes and ears**! üëÄü¶ª

---

:::note Chapter Completion
‚úÖ You've completed Chapter 8: Unity for High-Fidelity Rendering  
‚è±Ô∏è Estimated time to complete: 90 minutes  
üìä Progress: Module 2 - Chapter 3 of 5
:::
